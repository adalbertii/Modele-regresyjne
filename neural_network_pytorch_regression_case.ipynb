{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOzqwrT/1YcM8umiYv2zwu/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adalbertii/Modele-regresyjne/blob/main/neural_network_pytorch_regression_case.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pobranie niezbędnych bibliotek"
      ],
      "metadata": {
        "id": "E67fuRe4sH6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "data = fetch_california_housing()\n",
        "print(data.feature_names)\n",
        "X, y = data.data, data.target"
      ],
      "metadata": {
        "id": "0rExWGYvzgGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "EEil4UOYWx0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "id": "H7vBeM-WW1qI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[:5]"
      ],
      "metadata": {
        "id": "5MR_CVjUW6Q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y[:5]"
      ],
      "metadata": {
        "id": "IjzQ_oJpXRcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Budowa modelu"
      ],
      "metadata": {
        "id": "YtCZuykMzwBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "# definicja modelu\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(8, 24),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(24, 12),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(12, 6),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(6, 1)\n",
        ")"
      ],
      "metadata": {
        "id": "ogDKy9Pzz5Ki"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "HPoeqccbWUJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ustalenie funkcji straty oraz algorytmu optymalizacyjnego"
      ],
      "metadata": {
        "id": "rM-67Vd40-4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch.optim as optim\n",
        "# ustalenie funkcji straty oraz metody optymalizacji\n",
        "loss_fn = nn.MSELoss()  # mean square error\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "xv3jings1Jv6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Proces uczenia modelu"
      ],
      "metadata": {
        "id": "yhNlKDsl1cNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import numpy as np\n",
        "import torch\n",
        "import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# podział zbioru danych na dane treningowe i testowe\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)"
      ],
      "metadata": {
        "id": "32J2WKh31huv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ustalenie wartości hiperparametrów\n",
        "n_epochs = 20   # number of epochs to run\n",
        "batch_size = 10  # size of each batch\n",
        "batch_start = torch.arange(0, len(X_train), batch_size)\n",
        "\n"
      ],
      "metadata": {
        "id": "lIMZDAO-XwDe"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inicjalizacja wartości parametrów modelu\n",
        "best_mse = np.inf   # nieskończoność\n",
        "best_weights = None\n",
        "history = []\n",
        "\n"
      ],
      "metadata": {
        "id": "DhQla4HLX9Rc"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pętla treningowa modelu\n",
        "for epoch in range(n_epochs):\n",
        "    print('Epoka: ', epoch)\n",
        "    model.train()\n",
        "    with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
        "        bar.set_description(f\"Epoch {epoch}\")\n",
        "        for start in bar:\n",
        "\n",
        "            X_batch = X_train[start:start+batch_size]\n",
        "            y_batch = y_train[start:start+batch_size]\n",
        "\n",
        "            y_pred = model(X_batch)\n",
        "            loss = loss_fn(y_pred, y_batch)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            # aktualizacja wag\n",
        "            optimizer.step()\n",
        "\n",
        "            bar.set_postfix(mse=float(loss))\n",
        "    # weryfikacja parametru 'accuracy' na końcu każdej epoki\n",
        "    model.eval()\n",
        "    y_pred = model(X_test)\n",
        "    mse = loss_fn(y_pred, y_test)\n",
        "    mse = float(mse)\n",
        "    history.append(mse)\n",
        "    if mse < best_mse:\n",
        "        best_mse = mse\n",
        "        best_weights = copy.deepcopy(model.state_dict())\n",
        "\n"
      ],
      "metadata": {
        "id": "aWBJY66sYHXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_weights"
      ],
      "metadata": {
        "id": "sk0sHSezdQ64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# zaldowanie do modelu wyuczone wagi\n",
        "model.load_state_dict(best_weights)"
      ],
      "metadata": {
        "id": "qc5IQqrnYQXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Weryfikacja modelu"
      ],
      "metadata": {
        "id": "wT5Pa6hk1_A5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "print(\"MSE: %.2f\" % best_mse)\n",
        "print(\"RMSE: %.2f\" % np.sqrt(best_mse))\n",
        "plt.plot(history)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vtTFxQYJ2Io6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kompletny proces z uwzględnieniem standaryzacji danych wejściowych\n",
        "\n"
      ],
      "metadata": {
        "id": "otsdPPtS2x1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# pobranie danych\n",
        "data = fetch_california_housing()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# podział danych na dane treningowe i testowe\n",
        "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "RTQbESbU28Q3"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[:10]"
      ],
      "metadata": {
        "id": "xJ6b_5fzaoy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# standaryzacja danych\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train_raw)\n",
        "X_train = scaler.transform(X_train_raw)\n",
        "X_test = scaler.transform(X_test_raw)\n",
        "\n"
      ],
      "metadata": {
        "id": "aAabHlrFZsLl"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test[:10]"
      ],
      "metadata": {
        "id": "2ArR70gDa557"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#kowersja do tensora 2D(wymóg biblioteki pyTorch )\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)\n"
      ],
      "metadata": {
        "id": "DND9rzmUa2PO"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "id": "15OcakPQZzld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# definicja modelu\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(8, 24),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(24, 12),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(12, 6),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(6, 1)\n",
        ")\n",
        "\n",
        "# definicja funkcji straty ora metody optymalizatora\n",
        "loss_fn = nn.MSELoss()  # mean square error\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "n_epochs = 30\n",
        "batch_size = 10\n",
        "batch_start = torch.arange(0, len(X_train), batch_size)\n",
        "\n"
      ],
      "metadata": {
        "id": "4C_epqhsZ9Wc"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trening modelu\n",
        "best_mse = np.inf\n",
        "best_weights = None\n",
        "history = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    print('Epoka: ', epoch)\n",
        "    model.train()\n",
        "    with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
        "        bar.set_description(f\"Epoch {epoch}\")\n",
        "        for start in bar:\n",
        "\n",
        "            X_batch = X_train[start:start+batch_size]\n",
        "            y_batch = y_train[start:start+batch_size]\n",
        "\n",
        "            y_pred = model(X_batch)\n",
        "            loss = loss_fn(y_pred, y_batch)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            # aktualizacja wag\n",
        "            optimizer.step()\n",
        "\n",
        "            bar.set_postfix(mse=float(loss))\n",
        "    # ewaluacja modelu po każdej epoce\n",
        "    model.eval()\n",
        "    y_pred = model(X_test)\n",
        "    mse = loss_fn(y_pred, y_test)\n",
        "    mse = float(mse)\n",
        "    history.append(mse)\n",
        "    if mse < best_mse:\n",
        "        best_mse = mse\n",
        "        best_weights = copy.deepcopy(model.state_dict())\n",
        "\n"
      ],
      "metadata": {
        "id": "W6izdscBaCZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# załadowanie modelu wytrenowanymi wagami\n",
        "model.load_state_dict(best_weights)\n",
        "print(\"MSE: %.2f\" % best_mse)\n",
        "print(\"RMSE: %.2f\" % np.sqrt(best_mse))\n",
        "plt.plot(history)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "hXR12Tw7aTEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # predykcja na danych testowych (5 przykładow)\n",
        "    for i in range(5):\n",
        "        X_sample = X_test_raw[i: i+1]\n",
        "        X_sample = scaler.transform(X_sample)\n",
        "        X_sample = torch.tensor(X_sample, dtype=torch.float32)\n",
        "        y_pred = model(X_sample)\n",
        "        print(f\"{X_test_raw[i]} -> {y_pred[0].numpy()} (expected {y_test[i].numpy()})\")\n"
      ],
      "metadata": {
        "id": "DyOlBMVSab7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # predykcja na danych testowych (50 przykładow)\n",
        "    for i in range(50):\n",
        "        X_sample = X_test_raw[i: i+1]\n",
        "        X_sample = scaler.transform(X_sample)\n",
        "        X_sample = torch.tensor(X_sample, dtype=torch.float32)\n",
        "        y_pred = model(X_sample)\n",
        "        print(f\"{y_pred[0].numpy()} (expected {y_test[i].numpy()})\")"
      ],
      "metadata": {
        "id": "m5EE_fNP7isN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}