{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM3m56NwXYvsJ+phiwu/RGI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adalbertii/Modele-regresyjne/blob/main/neural_network_pytorch_regression_case.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pobranie niezbędnych bibliotek"
      ],
      "metadata": {
        "id": "E67fuRe4sH6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "data = fetch_california_housing()\n",
        "print(data.feature_names)\n",
        "X, y = data.data, data.target"
      ],
      "metadata": {
        "id": "0rExWGYvzgGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Budowa modelu"
      ],
      "metadata": {
        "id": "YtCZuykMzwBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "# Define the model\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(8, 24),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(24, 12),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(12, 6),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(6, 1)\n",
        ")"
      ],
      "metadata": {
        "id": "ogDKy9Pzz5Ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ustalenie funkcji straty oraz algorytmu optymalizacyjnego"
      ],
      "metadata": {
        "id": "rM-67Vd40-4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "# loss function and optimizer\n",
        "loss_fn = nn.MSELoss()  # mean square error\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "xv3jings1Jv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Proces uczenia modelu"
      ],
      "metadata": {
        "id": "yhNlKDsl1cNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import numpy as np\n",
        "import torch\n",
        "import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# train-test split of the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)\n",
        "\n",
        "# training parameters\n",
        "n_epochs = 20   # number of epochs to run\n",
        "batch_size = 10  # size of each batch\n",
        "batch_start = torch.arange(0, len(X_train), batch_size)\n",
        "\n",
        "# Hold the best model\n",
        "best_mse = np.inf   # init to infinity\n",
        "best_weights = None\n",
        "history = []\n",
        "\n",
        "# training loop\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
        "        bar.set_description(f\"Epoch {epoch}\")\n",
        "        for start in bar:\n",
        "            # take a batch\n",
        "            X_batch = X_train[start:start+batch_size]\n",
        "            y_batch = y_train[start:start+batch_size]\n",
        "            # forward pass\n",
        "            y_pred = model(X_batch)\n",
        "            loss = loss_fn(y_pred, y_batch)\n",
        "            # backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            # update weights\n",
        "            optimizer.step()\n",
        "            # print progress\n",
        "            bar.set_postfix(mse=float(loss))\n",
        "    # evaluate accuracy at end of each epoch\n",
        "    model.eval()\n",
        "    y_pred = model(X_test)\n",
        "    mse = loss_fn(y_pred, y_test)\n",
        "    mse = float(mse)\n",
        "    history.append(mse)\n",
        "    if mse < best_mse:\n",
        "        best_mse = mse\n",
        "        best_weights = copy.deepcopy(model.state_dict())\n",
        "\n",
        "# restore model and return best accuracy\n",
        "model.load_state_dict(best_weights)"
      ],
      "metadata": {
        "id": "32J2WKh31huv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Weryfikacja modelu"
      ],
      "metadata": {
        "id": "wT5Pa6hk1_A5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "print(\"MSE: %.2f\" % best_mse)\n",
        "print(\"RMSE: %.2f\" % np.sqrt(best_mse))\n",
        "plt.plot(history)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vtTFxQYJ2Io6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kompletny program\n",
        "- uwzględnienie standaryzacji danych wejściowych\n"
      ],
      "metadata": {
        "id": "otsdPPtS2x1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Read data\n",
        "data = fetch_california_housing()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# train-test split for model evaluation\n",
        "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
        "\n",
        "# Standardizing data\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train_raw)\n",
        "X_train = scaler.transform(X_train_raw)\n",
        "X_test = scaler.transform(X_test_raw)\n",
        "\n",
        "# Convert to 2D PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)\n",
        "\n",
        "# Define the model\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(8, 24),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(24, 12),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(12, 6),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(6, 1)\n",
        ")\n",
        "\n",
        "# loss function and optimizer\n",
        "loss_fn = nn.MSELoss()  # mean square error\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "n_epochs = 30   # number of epochs to run\n",
        "batch_size = 10  # size of each batch\n",
        "batch_start = torch.arange(0, len(X_train), batch_size)\n",
        "\n",
        "# Hold the best model\n",
        "best_mse = np.inf   # init to infinity\n",
        "best_weights = None\n",
        "history = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
        "        bar.set_description(f\"Epoch {epoch}\")\n",
        "        for start in bar:\n",
        "            # take a batch\n",
        "            X_batch = X_train[start:start+batch_size]\n",
        "            y_batch = y_train[start:start+batch_size]\n",
        "            # forward pass\n",
        "            y_pred = model(X_batch)\n",
        "            loss = loss_fn(y_pred, y_batch)\n",
        "            # backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            # update weights\n",
        "            optimizer.step()\n",
        "            # print progress\n",
        "            bar.set_postfix(mse=float(loss))\n",
        "    # evaluate accuracy at end of each epoch\n",
        "    model.eval()\n",
        "    y_pred = model(X_test)\n",
        "    mse = loss_fn(y_pred, y_test)\n",
        "    mse = float(mse)\n",
        "    history.append(mse)\n",
        "    if mse < best_mse:\n",
        "        best_mse = mse\n",
        "        best_weights = copy.deepcopy(model.state_dict())\n",
        "\n",
        "# restore model and return best accuracy\n",
        "model.load_state_dict(best_weights)\n",
        "print(\"MSE: %.2f\" % best_mse)\n",
        "print(\"RMSE: %.2f\" % np.sqrt(best_mse))\n",
        "plt.plot(history)\n",
        "plt.show()\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # Test out inference with 5 samples\n",
        "    for i in range(5):\n",
        "        X_sample = X_test_raw[i: i+1]\n",
        "        X_sample = scaler.transform(X_sample)\n",
        "        X_sample = torch.tensor(X_sample, dtype=torch.float32)\n",
        "        y_pred = model(X_sample)\n",
        "        print(f\"{X_test_raw[i]} -> {y_pred[0].numpy()} (expected {y_test[i].numpy()})\")\n"
      ],
      "metadata": {
        "id": "RTQbESbU28Q3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # Test out inference with 5 samples\n",
        "    for i in range(50):\n",
        "        X_sample = X_test_raw[i: i+1]\n",
        "        X_sample = scaler.transform(X_sample)\n",
        "        X_sample = torch.tensor(X_sample, dtype=torch.float32)\n",
        "        y_pred = model(X_sample)\n",
        "        print(f\"{y_pred[0].numpy()} (expected {y_test[i].numpy()})\")"
      ],
      "metadata": {
        "id": "m5EE_fNP7isN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}