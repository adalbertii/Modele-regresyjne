{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adalbertii/Modele-regresyjne/blob/main/mpg-case-regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHp3M9ZmrIxj"
      },
      "source": [
        "**Analiza modeli neuronowych**\n",
        "\n",
        "Wykorzystanie danych  [Auto MPG](https://archive.ics.uci.edu/ml/datasets/auto+mpg).\n",
        "\n",
        "[UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/).\n",
        "\n",
        "\n",
        "Demonstracja sposobu budowania modelu przeznaczonego do predykcji efektywnosci spalania paliwa.\n",
        "\n",
        "Tok działania:\n",
        "- pobranie danych i ich wstępna analiza\n",
        "- uproszczona standaryzacja danych\n",
        "\n",
        "- budowa modelu opratego na jednym neuronie i jednym atrybucie (zmiennej objaśnijającej)\n",
        "\n",
        "- budowa modelu składającego się z jednego neurona i wykorzystującego wszystkie zmienne objaśniajace\n",
        "\n",
        "*   budowa modelu składajacego się z 64 neuronów i jednej zmiennej objaśniajacej\n",
        "\n",
        "*    budowa modelu 64 neronowego ze wsystkimi zmiennymi objaśniajacymi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "moB4tpEHxKB3"
      },
      "outputs": [],
      "source": [
        "!pip install -q seaborn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "i7vUx-AbmOKm"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "1rRo8oNqZ-Rj"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xQKvCJ85kCQ"
      },
      "outputs": [],
      "source": [
        "np.set_printoptions(precision=3, suppress=True)\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFh9ne3FZ-On"
      },
      "source": [
        "### Pobranie danych do uczenia modeli\n",
        "Wykorzystanie modułu pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "CiX2FI4gZtTt"
      },
      "outputs": [],
      "source": [
        "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\n",
        "column_names = ['MPG', 'Liczba cylindrow', 'Pojemność skokowa', 'Moc', 'Waga',\n",
        "                'Przyspieszenie', 'Rok modelu', 'Pochodzenie']\n",
        "\n",
        "\n",
        "# mpg - miles per gallon\n",
        "raw_dataset = pd.read_csv(url,\n",
        "                          names=column_names,\n",
        "                          na_values='?', comment='\\t',\n",
        "                          sep=' ', skipinitialspace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oY3pMPagJrO"
      },
      "outputs": [],
      "source": [
        "# tworzymy kopie zbioru danych\n",
        "dataset = raw_dataset.copy()\n",
        "dataset.tail()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head(5)"
      ],
      "metadata": {
        "id": "pMEDrRLRcS1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## sprawdzamy charakterystykę atrybutów pobranego zbioru danych\n",
        "dataset.info()"
      ],
      "metadata": {
        "id": "xH74x-s5V32C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Atrybut 'pochodzenie' wymaga uwagi. To jest ukryta zmienna kategoryczna"
      ],
      "metadata": {
        "id": "e3JJ_EPPGcGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sprawdzamy rozkład statystyczne zmiennych\n",
        "dataset.describe().T"
      ],
      "metadata": {
        "id": "EqbzxPBYWBLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sprawdzamy korelacje zmiennych\n",
        "dataset.corr()['MPG'].sort_values(ascending=False)\n"
      ],
      "metadata": {
        "id": "aG6GGe21Xc0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px"
      ],
      "metadata": {
        "id": "T2T6bZm5X457"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sprawdzamy rozkłady wartości MPG dla różnych krajów pochodzenia\n",
        "px.histogram(dataset, x='MPG', width=1000, height=400, nbins=50, facet_col='Pochodzenie')"
      ],
      "metadata": {
        "id": "e-mqgQwqX7aQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sprawdzamy rozkłady wartości MPG w  zależności od liczny cylindów\n",
        "px.histogram(dataset, x='MPG', width=1000, height=400, nbins=50, facet_col='Liczba cylindrow')"
      ],
      "metadata": {
        "id": "hqFgwaE2aTTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sprawdzamy rozkłady wartości 'Rok modelu'\n",
        "px.histogram(dataset, x='Rok modelu', width=1000, height=400, nbins=50)"
      ],
      "metadata": {
        "id": "ijZv3uJwa0Hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MWuJTKEDM-f"
      },
      "source": [
        "### Wstępne przygotowanie danych\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEJHhN65a2VV"
      },
      "outputs": [],
      "source": [
        "# sprawdzamy czy występują braki danych\n",
        "dataset.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Istnieją braki danych.\n",
        "Dla uproszczenia usuwamy rekordy zawierajace braki danych"
      ],
      "metadata": {
        "id": "vEZV4-03w_me"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "4ZUDosChC1UN"
      },
      "outputs": [],
      "source": [
        "# Istnieją braki danych. Dla uproszczenia usuwamy rekordy zawierajace braki danych\n",
        "\n",
        "dataset = dataset.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.isna().sum()"
      ],
      "metadata": {
        "id": "3I35QueXghVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sprawdzenie czy występują duplikaty\n",
        "dataset[dataset.duplicated()]"
      ],
      "metadata": {
        "id": "KBD13dWMIXDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XKitwaH4v8h"
      },
      "source": [
        "Kolumna 'Pochodzenie` jet atrybutem kategorycznym, nie numerycznym .\n",
        "Nalezy zatem przeprowadić na tej kolumnie transfomację \"one-hot-encod\".\n",
        "W tym celu wykorzystana zostanie  metoda [pd.get_dummies]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "gWNTD2QjBWFJ"
      },
      "outputs": [],
      "source": [
        "# najpierw dokonujemy konwersji liczb (int64)  na oznaczenie tekstowe\n",
        "dataset['Pochodzenie'] = dataset['Pochodzenie'].map({1: 'USA', 2: 'Europe', 3: 'Japan'})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head(5)"
      ],
      "metadata": {
        "id": "X4mllba9lRgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.Pochodzenie.unique()"
      ],
      "metadata": {
        "id": "2SNGr1gNTf2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "ulXz4J7PAUzk"
      },
      "outputs": [],
      "source": [
        "# bardzo ważna operacja kodowania zmiennej kategorycznej 'Pochodzenie'\n",
        "dataset = pd.get_dummies(dataset,  columns=['Pochodzenie'], prefix='',prefix_sep='') ###"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head(5)"
      ],
      "metadata": {
        "id": "FglzdJKornvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cuym4yvk76vU"
      },
      "source": [
        "### Podział danych na dane treningowe i testowe\n",
        "\n",
        "Dane testowe zostaną wykorzystane do końcowej ewaluacji modelu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.shape"
      ],
      "metadata": {
        "id": "h0Epwcoklyin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "qn-IGhUE7_1H"
      },
      "outputs": [],
      "source": [
        "# operacja zwraca 80% danych wybranych losowo)\n",
        "train_dataset = dataset.sample(frac=0.8, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# usuwamy rekordy o indexach przydzilonych do rekordów z poprzedniej operacji\n",
        "test_dataset = dataset.drop(train_dataset.index)"
      ],
      "metadata": {
        "id": "Pnxr_uUmr7Zr"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.shape"
      ],
      "metadata": {
        "id": "SV7z-ejw0EDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset.shape"
      ],
      "metadata": {
        "id": "aAWuSdct8Chv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4ubs136WLNp"
      },
      "source": [
        "### Wstępna analiza danych\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRKO_x8gWKv-"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(train_dataset[['MPG', 'Liczba cylindrow', 'Pojemność skokowa', 'Waga','Moc']], diag_kind='kde')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gavKO_6DWRMP"
      },
      "source": [
        "Weryfikacja rozkładów statystycznych zmiennych objaśniajacych"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yi2FzC3T21jR"
      },
      "outputs": [],
      "source": [
        "train_dataset.describe().transpose()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Db7Auq1yXUvh"
      },
      "source": [
        "### Rozdzielenie zmiennych objaśniajacych od zmiennej objaśnianej (etykiety)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "t2sluJdCW7jN"
      },
      "outputs": [],
      "source": [
        "# najpierw same cechy (zmienne objaśniajaće)\n",
        "train_features = train_dataset.copy()\n",
        "test_features = test_dataset.copy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_features.head(5)"
      ],
      "metadata": {
        "id": "h-BMIh2hpogG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# teraz tzw. etykiety, czyli zmenne objaśniane\n",
        "# operacja poniższa zwraca warosci kolumny 'MPG' , jedocześnie usuwając tąkolumnę z ramki danych\n",
        "train_labels = train_features.pop('MPG')\n",
        "test_labels = test_features.pop('MPG')"
      ],
      "metadata": {
        "id": "K8DVpot6o8NY"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features.shape"
      ],
      "metadata": {
        "id": "9hOYEOiOnzNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features"
      ],
      "metadata": {
        "id": "475ooxnV4YeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels"
      ],
      "metadata": {
        "id": "RWklknbX2Erm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRklxK5s388r"
      },
      "source": [
        "## Normalizacja danych\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcmY6lKKbkw8"
      },
      "outputs": [],
      "source": [
        "# najpierw sprawdzam jak bardzo zróznicowane sa  wartościowo poszczególnych atrybutow\n",
        "train_dataset.describe().transpose()[['mean', 'std']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ywmerQ6dSox"
      },
      "source": [
        "\n",
        "Wartość średnia i odchylenie standardowe jest mocno żróżnicowane.\n",
        "\n",
        "Dobrą praktyką jest normalizacja cech, które używają różnych skal i zakresów.\n",
        "\n",
        "Jednym z powodów, dla których jest to ważne, jest to, że cechy są mnożone przez wagi modelu. Tak więc skala wyników i skala gradientów zależy od skali danych wejściowych.\n",
        "\n",
        "Chociaż model *może* uczyć  się bez normalizacji cech, normalizacja sprawia, że szkolenie jest znacznie bardziej stabilne.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFJ6ISropeoo"
      },
      "source": [
        "### Warstwa normalizująca  dane\n",
        "\n",
        "Tworzymy instancję normalizatora"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "JlC5ooJrgjQF"
      },
      "outputs": [],
      "source": [
        "normalizer = tf.keras.layers.Normalization(axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYA2Ap6nVOha"
      },
      "source": [
        "Dokonujemy normalizacji zmiennych objaśniajacych :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "CrBbbjbwV91f"
      },
      "outputs": [],
      "source": [
        "# metoda \"adapt\" wymaga obiektu np.array\n",
        "normalizer.adapt(np.array(train_features))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGWKaF9GSRuN"
      },
      "source": [
        "Gdy warstwa jest wywoływana, zwraca dane wejściowe, z każdą cechą niezależnie znormalizowaną:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2l7zFL_XWIRu"
      },
      "outputs": [],
      "source": [
        "# to jest tylko symulacja procesu normalizacji\n",
        "# demonstracja działania normalizotora\n",
        "# pobieramy 1 wiersz\n",
        "first = np.array(train_features[:1])\n",
        "\n",
        "with np.printoptions(precision=2, suppress=True):\n",
        "  print('Wiersz przed normalizacja:', first)\n",
        "  print()\n",
        "  print('Wiersz znormalizowany    :', normalizer(first).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6o3CrycBXA2s"
      },
      "source": [
        "## Regresja liniowa\n",
        "\n",
        "Przed zbudowaniem głebokiej sieci neuronowej przeanalizujemu budowę liniowej sieci z jedną i wieloma cechami (zmiennymi objaśniajacymi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFby9n0tnHkw"
      },
      "source": [
        "### Regresja lionowa z jedną zmienną objaśniajacą\n",
        "\n",
        "Predykcja 'MPG' na podstwie zmiennej 'Moc'.\n",
        "\n",
        "Sieć neuronowa będzie zbudowana z dwóch warstw:\n",
        "\n",
        "- warstwy normalizującej atrybut wejściowy 'moc` (przy użyciu klasy  `tf.keras.layers.Normalization).\n",
        "- warstwy Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gJAy0fKs1TS"
      },
      "outputs": [],
      "source": [
        "horsepower = np.array(train_features['Moc'])\n",
        "horsepower\n",
        "# te dane nie sa jeszcze wyskalowane. Zrobi to odpowiednia warstwa sieci neuronowej"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tworzymy pierwsza warstwe sieci\n",
        "horsepower_normalizer = layers.Normalization(input_shape=[1,], axis=None)"
      ],
      "metadata": {
        "id": "qO7rR1LxzghD"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# przekazujemy metodzie tylko jedną zmienna objasniajaća\n",
        "horsepower_normalizer.adapt(horsepower)"
      ],
      "metadata": {
        "id": "Mt1MiTxIu3Ha"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NVlHJY2TWlC"
      },
      "source": [
        "Budowa modelu Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0sXM7qLlKfZ"
      },
      "outputs": [],
      "source": [
        "horsepower_model = tf.keras.Sequential([\n",
        "    horsepower_normalizer,\n",
        "    layers.Dense(units=1)# domyślie przyjmuje, że funkcja aktywacji jest lioniowa\n",
        "])\n",
        "\n",
        "horsepower_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSkanJlmmFBX"
      },
      "source": [
        "Po zbudowaniu modelu należy go skompilować.\n",
        "\n",
        "Na tym etapie kluczowy jest dobór hiperparametrów modelu:\n",
        "*   'loss'\n",
        "*   'optimizer'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "JxA_3lpOm-SK"
      },
      "outputs": [],
      "source": [
        "horsepower_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.1), # 'Adam' jeden z stochastycznych mtod gradientowych (Stochastic Gradient Descent)\n",
        "    loss='mean_absolute_error')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3q1I9TwnRSC"
      },
      "source": [
        "Proces uczenia modelu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iSrNy59nRAp"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "# zmienna history będzie zawierała pełną charakterystyką zrealizowanego procesu uczenia\n",
        "history = horsepower_model.fit(\n",
        "    train_features['Moc'],\n",
        "    train_labels,\n",
        "    epochs=100,\n",
        "    verbose=1,\n",
        "    validation_split = 0.2) #Oblicza wyniki walidacji na 20% danych treningowych"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQm3pc0FYPQB"
      },
      "source": [
        "Wizualizacja procesu uczenia przy użyciu statystyk zapisanych w obiekcie `history`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCAwD_y4AdC3"
      },
      "outputs": [],
      "source": [
        "hist = pd.DataFrame(history.history)\n",
        "hist.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist['epoch'] = history.epoch\n",
        "hist.head()"
      ],
      "metadata": {
        "id": "KJB4M9GDwMe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "9E54UoZunqhc"
      },
      "outputs": [],
      "source": [
        "#definiujemy procedure\n",
        "def plot_loss(history):\n",
        "\n",
        "  #--------------------------\n",
        "  plt.plot(history.history['loss'], label='loss')\n",
        "  plt.plot(history.history['val_loss'], label='val_loss')\n",
        "  #--------------------------\n",
        "\n",
        "  plt.ylim([0, 10])\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Error [MPG]')\n",
        "  plt.legend()\n",
        "  plt.grid(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYsQYrIZyqjz"
      },
      "outputs": [],
      "source": [
        "plot_loss(history)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "horsepower_model.summary()"
      ],
      "metadata": {
        "id": "2uoc63qQkmNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# wyświetlimy wyznaczone współczynniki wagowe modelu\n",
        "\n",
        "wagi = horsepower_model.get_weights()\n",
        "wagi"
      ],
      "metadata": {
        "id": "7RB89VPsj80r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMNrt8X2ebXd"
      },
      "source": [
        "Zachowanie rezultatów na poźniejsze porównania"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "kDZ8EvNYrDtx",
        "outputId": "c04788a4-4164-4979-96d2-13f07d6ec040",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 3ms/step - loss: 3.6384\n"
          ]
        }
      ],
      "source": [
        "# tworzymy słownik dla analizy porównawczej - oceny wskażników ewaluacyjnych (stopnia dokładności predykcyjnej modelu)\n",
        "test_results = {}\n",
        "\n",
        "# !!! ewaluacja modelu\n",
        "# obliczamy wskaznik 'loss' dla danych testowych w opariu o metodę \"evaluate\"\n",
        "test_results['horsepower_model'] = horsepower_model.evaluate(\n",
        "    test_features['Moc'], # dane dla jednej zmiennej objaśnijacej\n",
        "    test_labels, # dla danych !!!! TESTOWYCH\n",
        "    verbose=1) # etykiety dla danych tesowych"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#wynik (loss) dla danych testowych , dla modelu z jednym neuronem\n",
        "test_results"
      ],
      "metadata": {
        "id": "-fkFptFxmhFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0qutYAKwoda"
      },
      "source": [
        "Ponieważ jest to regresja dla pojedynczej zmiennej, łatwo jest wyświetlić prognozy modelu jako funkcję danych wejściowych (zmiennej 'Moc')."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "xDS2JEtOn9Jn"
      },
      "outputs": [],
      "source": [
        "# generujemy sztuczne dane  testowe  do przeprowadzenia weryfikacji wyników predykcji\n",
        "x = tf.linspace(5.0, 150, 251)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dokonujemy predykcji MPG na podstwie danych testowych\n",
        "y = horsepower_model.predict(x)"
      ],
      "metadata": {
        "id": "ynkiyBPvVAPT",
        "outputId": "83947fe8-d0b2-4b71-d81c-987b6d372762",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y[:5]"
      ],
      "metadata": {
        "id": "obH6dMZ32_Jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "rttFCTU8czsI"
      },
      "outputs": [],
      "source": [
        "# definiuję procedurę do tworzenia wykresu\n",
        "# wykres złożony  z danych treningowych  oraz wyników predykcji dla sztucznych danych \"testowych\"\n",
        "def plot_horsepower(x, y):\n",
        "\n",
        "# ----------------------------------------------\n",
        "  plt.scatter(train_features['Moc'], train_labels, label='Data') # dane rzeczywiste\n",
        "\n",
        "  plt.plot(x, y, color='r', label='Predictions') # wyniki predykcji\n",
        "# ----------------------------------------------\n",
        "\n",
        "  plt.xlabel('Horsepower')\n",
        "  plt.ylabel('MPG')\n",
        "  plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7l9ZiAOEUNBL"
      },
      "outputs": [],
      "source": [
        "plot_horsepower(x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yk2RmlqPoM9u"
      },
      "source": [
        "### =====================================================================\n",
        "### Regresja liniowa z wieloma zmiennymi objaśniajacymi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PribnwDHUksC"
      },
      "source": [
        "Ponownie budujemy dwuetapowy model sekwencyjny Keras z pierwszą warstwą będącą normalizatorem (tf.keras.layers.Normalization(axis=-1)), który zdefiniowaliśmy wcześniej **[~~ komórka [42]** i dostosowali  do całego zbioru danych (z wszystkimi zmiennymi objaśniajacymi)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "ssnVcKg7oMe6"
      },
      "outputs": [],
      "source": [
        "# definujemy taki sam jak poprzednio model (z taką samą topologię)\n",
        "linear_model = tf.keras.Sequential([\n",
        "    normalizer, # obiekt normalize zawiera tym razem  znormalizowane wartości wszystkich atrybutów(zmiennych objasniających)\n",
        "    layers.Dense(units=1) # neuron z lioniową funkcją aktywacji\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eINAc6rZXzOt"
      },
      "source": [
        "Kompilujemy model i przechodzimy do jego uczenia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "A0Sv_Ybr0szp"
      },
      "outputs": [],
      "source": [
        "linear_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
        "    loss='mean_absolute_error')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZoOYORvoTSe"
      },
      "outputs": [],
      "source": [
        "# ustawiam takie same wartości hiperparametrów jak poprzednio\n",
        "%%time\n",
        "history = linear_model.fit(\n",
        "    train_features,# wszzystkie zmienne objasniajace\n",
        "    train_labels,\n",
        "    epochs=100,\n",
        "    verbose=1,\n",
        "    validation_split = 0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdxiCbiNYK2F"
      },
      "source": [
        "Wykorzystując wszystkie zmienne objaśniajace uzyskujemy znacznie niższy błąd treningowy i walidacyjny niż w poprzedniom modelu (`horsepower_model`)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model.summary()"
      ],
      "metadata": {
        "id": "pNIx0AAegqmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sWO3W0koYgu"
      },
      "outputs": [],
      "source": [
        "plot_loss(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyN49hIWe_NH"
      },
      "source": [
        "Zapisujemy wyniki ewaluacji modelu dla danych testowych"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNC3D1DGsGgK"
      },
      "outputs": [],
      "source": [
        "# przeprowadzamy ewaluację modelu\n",
        "test_results['linear_model'] = linear_model.evaluate(\n",
        "    test_features, test_labels, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I porównajmy wskażniki ewaluacyjne dla dwóch modeli  z jedną zmienna objaśniającą i wieloma zmiennymi objasniającymi"
      ],
      "metadata": {
        "id": "cMzAWxZEdsK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_results)"
      ],
      "metadata": {
        "id": "EoiCI3nK5-Iz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pierwsze wnioski ???**"
      ],
      "metadata": {
        "id": "ZrjuKGtK42Vs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmjdzxKzEu1-"
      },
      "source": [
        "## Regresja za pomocą sieci głębokich [deep neural network (DNN)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DT_aHPsrzO1t"
      },
      "source": [
        "\n",
        "Zaimplementujemy  modele DNN z pojedynczym i wieloma wejściami (uwzględniając jedną  i wszystkie zmienne objaśniające).\n",
        "\n",
        "Kod jest zasadniczo taki sam, z wyjątkiem tego, że model jest rozszerzony o niektóre \"ukryte\" warstwy nieliniowe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SWtkIjhrZwa"
      },
      "source": [
        "Modele te będą zawierać kilka warstw więcej niż model liniowy:\n",
        "\n",
        "\n",
        "\n",
        "*   Warstwa normalizacji, jak poprzednio (z 'horsepower_normalizer' dla modelu z jednym wejściem i 'normalizer' dla modelu z wieloma wejściami).\n",
        "\n",
        "*   Dwie ukryte, nieliniowe warstwy Dense z nieliniowością funkcji aktywacji ReLU (relu).\n",
        "*   Liniowa warstwa Dense z pojedynczym wyjściem.\n",
        "\n",
        "Oba modele będą korzystać z tej samej procedury uczenia, więc metoda kompilacji jest zawarta w poniższej funkcji build_and_compile_model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "c26juK7ZG8j-"
      },
      "outputs": [],
      "source": [
        "def build_and_compile_model(norm):\n",
        "  model = keras.Sequential([\n",
        "      norm,\n",
        "      layers.Dense(64, activation='relu'),\n",
        "      layers.Dense(64, activation='relu'),\n",
        "      layers.Dense(1)# funkcja aktywacji liniowa\n",
        "  ])\n",
        "\n",
        "  model.compile(loss='mean_absolute_error',\n",
        "                optimizer=tf.keras.optimizers.Adam(0.001))\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c51caebbc0d"
      },
      "source": [
        "### Regresja przy użyciu DNN i pojedynczego wejścia (jedna zmienna objaśniająca )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvu9gtxTZR5V"
      },
      "source": [
        "Zbudujemy model DNN  tylko z `'Moc`` jako danymi wejściowymi i `horsepower_normalizer` (zdefiniowanym wcześniej) jako warstwą normalizacji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "cGbPb-PHGbhs"
      },
      "outputs": [],
      "source": [
        "dnn_horsepower_model = build_and_compile_model(horsepower_normalizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sj49Og4YGULr"
      },
      "source": [
        "Model ten ma o wiele więcej parametrów do wytrenowania niż modele liniowe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ReAD0n6MsFK-"
      },
      "outputs": [],
      "source": [
        "# !!!! przedyskutować topologię  sieci\n",
        "dnn_horsepower_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-qWCsh6DlyH"
      },
      "source": [
        "Proces trenowania modelu (za pomocą metody  Keras `Model.fit`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sD7qHCmNIOY0"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "history = dnn_horsepower_model.fit(\n",
        "    train_features['Moc'],\n",
        "    train_labels,\n",
        "    validation_split=0.2,\n",
        "    verbose=1, epochs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dArGGxHxcKjN"
      },
      "source": [
        "Ten model radzi sobie nieco lepiej niż jednowejściowy  model liniowy `horsepower_model`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcF6UWjdCU8T"
      },
      "outputs": [],
      "source": [
        "plot_loss(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TG1snlpR2QCK"
      },
      "source": [
        "Jeśli wygenerujemy wykres predykcji ajko funkcji zmiennej 'Moc' łatwo zauważyć jak ten model wykorzystuje nieliniowość zapewnianą przez ukryte warstwy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPF53Rem14NS"
      },
      "outputs": [],
      "source": [
        "x = tf.linspace(50.0, 250, 251)\n",
        "y = dnn_horsepower_model.predict(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsf9rD8I17Wq"
      },
      "outputs": [],
      "source": [
        "plot_horsepower(x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxCJKIUpe4io"
      },
      "source": [
        "Zapisujemy rezultat ewaluacji dla tego modelu (na danych testowych)\n",
        "Na końcu notebok- a przedstwimy porównaie tego wskażnika dla wszystkich modeli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "bJjM0dU52XtN"
      },
      "outputs": [],
      "source": [
        "test_results['dnn_horsepower_model'] = dnn_horsepower_model.evaluate(\n",
        "    test_features['Moc'], test_labels,\n",
        "    verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_results"
      ],
      "metadata": {
        "id": "-mO5OWjw7vHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_2Btebp2e64"
      },
      "source": [
        "### Regresja przy wykorzystaniu modelu DNN i wszystkich zmiennych objaśniajacych"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKFtezDldLSf"
      },
      "source": [
        "Powtórzymy poprzedni proces, używając wszystkich dane wejściowe. Wydajność modelu nieznacznie poprawia się na zestawie danych walidacyjnych."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0mhscXh2k36"
      },
      "outputs": [],
      "source": [
        "# podajemy procedurze pełny normalizator (z wszystkimi zmiennymi objasniającymi)\n",
        "dnn_model = build_and_compile_model(normalizer)\n",
        "dnn_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXDENACl2tuW"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "history = dnn_model.fit(\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    validation_split=0.2,\n",
        "    verbose=1, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9Dbj0fX23RQ"
      },
      "outputs": [],
      "source": [
        "plot_loss(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWoVYS34fJPZ"
      },
      "source": [
        "Zapisujemy rezultat ewaluacji tego modelu (dla danych testowych)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "id": "-bZIa96W3c7K"
      },
      "outputs": [],
      "source": [
        "test_results['dnn_model'] = dnn_model.evaluate(test_features, test_labels, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiCucdPLfMkZ"
      },
      "source": [
        "## Porównanie wydajności zbudowanych modeli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5_ooufM5iH2"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(test_results, index=['Mean absolute error [MPG]']).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ft603OzXuEZC"
      },
      "source": [
        "### Predykcja\n",
        "\n",
        "Dokonamy teraz predykcji za pomocą `dnn_model` **na zbiorze testowym** używając Keras `Model.predict`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xe7RXH3N3CWU"
      },
      "outputs": [],
      "source": [
        "test_predictions = dnn_model.predict(test_features).flatten()\n",
        "\n",
        "a = plt.axes(aspect='equal')\n",
        "\n",
        "#------------------------------------------------------\n",
        "plt.scatter(test_labels, test_predictions)\n",
        "#------------------------------------------------------\n",
        "\n",
        "plt.xlabel('True Values [MPG]')\n",
        "plt.ylabel('Predictions [MPG]')\n",
        "\n",
        "#------------------------------------------------------\n",
        "lims = [0, 50]\n",
        "plt.xlim(lims)\n",
        "plt.ylim(lims)\n",
        "_ = plt.plot(lims, lims)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Im bliższe skupienie punktów będących wynikami predykcji wokół prostej (rzeczywista wartosc =  przewidywna wartosc) tym lepiej"
      ],
      "metadata": {
        "id": "pRhWahSfF7VM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19wyogbOSU5t"
      },
      "source": [
        "Wygląda na to, że model przewiduje dość dobrze.\n",
        "\n",
        "Teraz należy sprawdzić rozkład błędów:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-OHX4DiXd8x"
      },
      "outputs": [],
      "source": [
        "error = test_predictions - test_labels\n",
        "plt.hist(error, bins=25)\n",
        "plt.xlabel('Prediction Error [MPG]')\n",
        "_ = plt.ylabel('Count')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "regression.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}